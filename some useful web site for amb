https://github.com/alison-carrera/mabalgs/blob/master/Monte_Carlo_Simulation_Example.ipynb

https://github.com/niravnb/Multi-armed-bandit-algortihms/tree/master/Thompson%20Sampling

https://github.com/eigenfoo/wanderings/tree/afcf37a8c6c2a2ac38f6708c1f3dd50db2ebe71f
https://github.com/ezraerb/BayseanBandit/blob/master/bandit.py
